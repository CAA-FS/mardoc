#+TITLE: Pending Technical Requirements for Rotational Analysis
#+AUTHOR: T. Spoon
#+DATE: 6 June 2016
#+STARTUP: showall

* Front End

** Project Management

*** Run Configuration / Definition

    MARATHON projects require a significant amount of input across
    multiple domains.  MARATHON has a fairly mature data model, which
    covers most of the data requirements for studies spanning the last
    decade.  Still, the analyst must manage a relatively bulky set of
    data.  Even with some pre-run data validation, human errors are
    prevalent.

    Making it simpler to define and configure MARATHON runs, to
    include deriving new runs from old, and version controlling runs,
    would reduce human error significantly and improve the
    quality of life for analysts.
    
** Pre-Run Verification / Input Data Validation

    There are certain structural properties that the input must
    maintain before MARATHON can compute a result from input.
    MARATHON currently examines a subset of these properties and
    reports them to the user prior to running.  Scoping rules
    (matching supply to demand) are one example.  MARATHON will try to
    detect which elements of supply cannot be used and which demand
    cannot be filled, reporting the results as "out of scope."  Often
    times the scoping is unintentional and the result of data errors,
    which the analyst can fix when they are made aware.

    Similar errors were rife in recent analysis for TAA.  Anecdotal
    evidence indicates that copy/paste errors created problems in many
    of the TAA runs. Having some automated structural verification
    will help prevent these classes of errors in the future.

* Post-Run Analysis Platform

** Static Analysis

** UI

- ORSA-Friendly  
- Likely Linked to Excel
- Structured Workflow

I currently have a simple workflow that allows the user to edit a
project in an excel file, and set the file /within clojure/ as a
linked project.  When runs are requested, the linked project is
checked for changes, and if there are changes the tables in the
project (workbook sheets) are reloaded.  This currently gives a decent
approximation of the edit/run feedback loop analysts were familiar
with.

We could do a lot more with this though, and I know the analysts would
appreciate it.  Probably go for a client/server route, with the client
being browser-based.  Bring in all the goodies from
Javascript/Clojurescript land (or not, even simple Barrybase like
static HTML would be okay).


* Back End

** Verification / Test Design

Define invariants that form the basis for testing.  Expand the
existing test suite to incorporate new invariants.  Strengthen
confidence in the current implementation.  Find errors.  Break
MARATHON.

MARATHON currently uses the built-in testing platform =clojure.test=
to perform automated regression testing.  Currently, tests are
designed and added in a fairly organic manner rather than following a
specific methodology like Test Driven Development: functionality is
implemented and experimented with "live" in the Clojure Read Evaluate
Print Loop (REPL).  This allows for rapid development and easy
creation of useful regression tests (often times output is copied
verbatim from the output).

There are benefits to approaching testing more systematically.  We can
do so with tests that are designed a-priori, with a focus on testing a
set of invariants.

Another approach is property-based or generative testing, using
libraries like =clojure.quickcheck=.  The libraries generate random
data to test supposed invariants rather than using -- typically --
single points of test data.  They also stress the system across a more
chaotic set of inputs and typically lead to stronger systems (see
Netflix's Chaos Monkey for an example).

Expanding MARATHON's test suite in either of these directions would be
a boon toward verification and continued development.

** Data Visualization

Graphics and charts are the medium through which we tell the story of
a Rotational Analysis case.  Currently, we use a variety of tools to
accomplish this:

    - an integrated set of charting and custom graphics built around
      the Incanter/JFreeChart libraries,
    - the custom spork.sketch library,
    - the Piccolo2D scenegraph library,
    - R, and
    - Excel.

These are desktop, client-side solutions.  There a plethora of
advanced data visualization solutions in other domains, such as
Javascript, that can be leveraged to provide useful visualizations and
compelling animation.  Dedicating research toward developing and
enhancing our visualization capability would directly enhance our
ability to communicate with -- and for -- sponsors.  Specifically, the
domain of animated visualizations tied to simulation has been a topic
of intense interest due to resonance with sponsors.

** Distributed Simulation

Some methodologies, such as designing force structure experiments and
Portfolio Analysis, require setting up, computing, and aggregating
results from a sizeable number of simulation runs.  Our previous
bottleneck was the limitation of running MARATHON v3 in Excel.  Due to
dependence on Office, and the way automation worked with VBA
(including a proclivity for memory leaks), distributing runs required
manual interaction.  With the move to Clojure in MARATHON v4, we
specifically intend for MARATHON to run "headless", without the need
for user interaction, directed by a script or other processing harness.
The only requirement is host support for the Java Virtual Machine.

MARATHON would benefit from dedicated research and development in
determining how to leverage the advantages of Clojure and the JVM to
support executing and processing distributed runs.  Currently, we can
trivially perform multiple MARATHON runs in parallel on the same
machine -- thanks to Clojure -- but MARATHON has yet to be adapted to
run on a cluster.  We should actively target the CAA Cluster and the
Army HPC labs clusters to expand the scope of our rotational analyses.

** Simulation Run Aggregation / Post Processing

Collecting, processing, and generally munging all of the data from a
MARATHON run is no small matter.  There are event-stepped records and
events for every entity's history in the simulation, as well as demand
history deployment history, policy history, cycle history, and many
other temporal data sets.  Sampling intervals are inconsistent across
the data, due to the sparse event-driven sampling, so the underlying
continuous signal must be reconstructed from multiple discrete
signals.

The current Clojure-based post processor does this and more, in a
more-or-less efficient fashion.  However, the architecture is far from
elegant, and the different processing workflows are not clear to the
average user.  We also have no defined way to aggregate multiple run
cases.  Results are currently post-processed relative to a case.
Scaling up the ability to do things like stochastic runs, or
aggregating results from a large set of runs, will require extending
or supplanting the current post processor.

** Force Structure Search / Design of Experiment

Develop a library around MARATHON v4 to perform higher-order analyses
based on automated experimentation and / or search.  Ex. utilize
classical and other search techniques to perform Portfolio Analysis,
searching for force structure mixtures that are robust across a range
of force structure demand cases (i.e. demand futures).  Leverage or
replace the work done in building the existing Stoke library (a
prototype implementation of Portfolio Analysis with stochastic demand
futures).  Expand on the DOE infrastructure built for data farming, in
collaboration with the Naval Post Graduate School, for the TMAS study.

This is an area rife with opportunity for publishable research and
extending the state-of-the-art for Rotational Analysis. It also may
make future analysis "easier" on the analyst, since we may be able to
shift away from specifying exact force structure mixtures and move
toward specifying desirable properties of force structure mixtures and
letting the computer find them for us.

This topic deserves more space than I have time to dedicate to it.

** Simulation Engine

At the high level, the engine is merely a function that computes a
resulting MARATHON simulation state from an input state -- in other
words a state transition function. The simulation, then, is the
repeated application of this state transition function, using
successive computed states as input for the next application.  Since
we are using persistent data structures by default, we actually retain
a stream of all previously computed states, or the simulation history,
which are indexed by the time of the event that "caused" the
transition to be invoked.  Computing a successive state is equivalent
to taking an "event step" in a discrete event simulation, and we do
indeed maintain a persistent queue of pending events as part of the
state.  The state transition function uses the next pending event, and
the initial state, to "handle" the event in simulation parlance.  The
vast majority of the architecture follows the functional programming
paradigm.

The architecture for MARATHON is based on two primary concepts: an
Entity Component System (or Entity Store), and the notion of Behavior
Trees for entity behavior. The ECS allows us to store our entity
information in something akin to a normalized database, that makes it
easy to query entities by property, and modify them in the small.
  
We compose functional "systems" on top of the entity store to compute
domain-specific state transitions.  For instance, we have a supply
system that computes changes in entities in the supply, such as
movement and policy changes.  The demand system activates and
deactivates demand entities.  While there are several systems, they
are all composed -- via function composition -- into the "engine"
state transition function.

Complex entity behaviors are implemented using Behavior Trees.
Behaviors are simple functions that can be evaluated in the context of
a behavior environment.  When evaluated, they return a resulting
behavior environment -- either success or failure.  Behaviors can
be composed using higher-order behavior functions, such as =->and=,
=->or=, =->if=, to define a sophisticated behavior from smaller,
simpler behaviors.  As with any other behavior, this behavior can
provided as input, along with a behavior context, to the behavior
evaluation function, and will return success or failure.  Behaviors
let us define small, composeable elements of entity behavior that
apply to one or many entities.  Behavior Trees are an alternate way to
implement the functionality of Hierarchical Finite State Machines.

The current design promotes the use of persistent data structures and
functional-programming design to make testing easier, hopefully
simplify the design, illuminate functional dependencies, and exploit
persistent values.  For instance, if we retain the entire simulation
history from a preceding time step [cheaply and efficiently due to the
magic of persistent data structures] we can implement backtracking and
revisit the past.  This opens up the ability to easily "look ahead"
and additional forms of search.

The functional design also makes certain elements obvious (if not
easy) candidates for parallelization.  Since we know the data
dependencies, we can -- in theory -- farm out the work efficiently and
possibly reap performance rewards.

There are many opportunities for revising the current architecture.
For instance, we may implement a strategy for using mutable data
structures in cases where persistence is no longer useful
(particularly where more performance may be reaped).  Providing a
mutable "backend" for MARATHON shouldn't be too hard to accomplish,
given that the entirety of the data lives in the entity store.  We may
also prefer to formalize the concurrency model that is currently being
simulated: Entities are scheduled across multiple abstract threads of
computation, and are "woken" during behavior evaluation.  MARATHON
currently schedules everything and creates the facade of entities
updating concurrently, when in reality, everything is synchronized and
computations are performed on a single thread.  There are formal
concurrency models -- the Actor model from Erlang / Akka and
Communicating Sequential Processes from Go and =clojure.core.async= --
which may provide a more elegant solution than the current
implementation.  Additionally, embracing a concurrency model may ease
the transition to distributed simulation going forward.  This is an
area that could use significant research and development.
